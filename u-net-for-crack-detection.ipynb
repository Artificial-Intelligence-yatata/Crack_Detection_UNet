{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install glob --upgrade\npip install os --upgrade\npip install numpy --upgrade\npip install pandas --upgrade\npip install time --upgrade\npip install matplotlib --upgrade\n\npip install cv2 --upgrade\n\npip install torch --upgrade\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pip install torchstat\n!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-03-11T19:38:59.240660Z","iopub.execute_input":"2023-03-11T19:38:59.241188Z","iopub.status.idle":"2023-03-11T19:41:29.610159Z","shell.execute_reply.started":"2023-03-11T19:38:59.241144Z","shell.execute_reply":"2023-03-11T19:41:29.608183Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe007a5a6d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe007aa8950>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe007aa8390>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe007aa8310>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe007aa8b50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchsummary (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torchsummary\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import glob\nimport os\nimport numpy # linear algebra\nimport pandas # data processing, CSV file I/O (e.g. pd.read_csv)\nimport time\nimport matplotlib\nimport matplotlib.pyplot\nimport cv2\nimport random\nimport sklearn\nimport sklearn.model_selection\n\nimport torch\n#import torchvision\nimport torchsummary \nimport torchmetrics","metadata":{"execution":{"iopub.status.busy":"2023-03-11T19:37:35.429122Z","iopub.execute_input":"2023-03-11T19:37:35.429576Z","iopub.status.idle":"2023-03-11T19:37:39.382539Z","shell.execute_reply.started":"2023-03-11T19:37:35.429534Z","shell.execute_reply":"2023-03-11T19:37:39.380677Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2491499640.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"],"ename":"ModuleNotFoundError","evalue":"No module named 'torchsummary'","output_type":"error"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"class customDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, data = None, data_test = None, test_factor = 0.2, for_training = True,\n                 data_type = None,\n                 transform = None, multiple_processes = 2, seed = None):\n        \n        \n        self.problem = \"segmentation\"\n        self.problem_type = \"supervised\"\n        \n                \n        self.data_loaded = False\n        \n        self.parameter_check(data = data, data_test = data_test, test_factor = test_factor,\n                             for_training = for_training,\n                             data_type = data_type, multiple_processes = multiple_processes, seed = seed)\n        \n        \n        \n        \n        try:\n            self.transform = transform\n        except NameError:\n            self.transform = None\n        \n      \n    def parameter_check(self, data, data_test, test_factor, for_training, data_type, multiple_processes, seed):\n                   \n        data_type.lower()\n        if (data_type != \"alphanumeric\" or data_type != \"image\" or\n            data_type != \"audio\" or data_type != \"video\" or\n            data_type != \"mix\"):\n            \n            \n            #TODO raise error \n            pass\n        \n        self.data_type = data_type\n        \n        \n        \n        self.multiple_processes = multiple_processes\n        self.for_training = for_training\n        \n        \n        if (data != None):\n            self.generate_dataset(data, data_type)\n        \n        if (data_test is None):\n            self.train_test_split(test_factor = test_factor, seed = seed)\n        \n        else:\n            self.data_train = self.data\n            self.data_test = data_test\n            \n            self.train_size = len(self.data_train)\n            self.test_size = len(self.data_test)\n            self.test_factor = len(self.data_test)/len(self.data)\n            \n            \n    def initiate_process(self, multiple_processes, batch_size, shuffle, drop_last):\n        \n        self.preprocessing()\n        \n        self.init_dataloader(for_training = self.for_training, batch_size = batch_size, multiple_processes = multiple_processes,\n                             shuffle = shuffle, drop_last = drop_last)\n        \n        \n            \n    def generate_dataset (self, data, data_type):\n        \n        \"\"\"\n        Data can be a dataset, data_directory, a Database, \n        \"\"\"\n        start_time = time.process_time()\n        \n        if os.path.isdir(data):\n             \n            \n            if (data_type == \"alphanumeric\"):\n                pass\n        \n            elif (data_type == \"image\" and self.problem_type == \"supervised\"):\n                \n                # Must have image data and class (Y) data\n                \n                \n                if (self.problem == \"classification\"):\n                    pass\n                elif (self.problem == \"detection\"):\n                    pass\n                elif (self.problem == \"segmentation\"):\n                    \n                    # must have Binary classes (Mask of Yes Data and Mask of No Data)\n                    # define directory paths\n                    data_directory = data\n                    \n                    classes = list(map(os.path.basename,[f.path for f in os.scandir(data_directory) if f.is_dir()]))\n    \n                    image_folders = [\"images\", \"imgs\", \"image\", \"Images\", \"Imgs\", \"Image\"]\n                    mask_folders = [\"masks\", \"mks\", \"mask\", \"Masks\", \"Mks\", \"Mask\"]\n            \n                     # initialize empty lists for image and mask paths\n                    image_paths = []\n                    mask_paths = []\n                    \n                    # iterate through image directories and add image paths to list\n                    for classe in classes:\n                        classe_directory = os.path.join(data_directory, classe)\n                        \n                        for image_folder in image_folders:\n                            path = os.path.join(classe_directory, image_folder)\n                            \n                            if os.path.exists(path):\n                                                               \n                                image_paths.extend(glob.glob(path + '/*.[jJ][pP][gG]', recursive=False))\n                                image_paths.extend(glob.glob(path + '/*.[jJ][pP][eE][gG]', recursive=False))\n                                image_paths.extend(glob.glob(path +'/*.png', recursive=False))\n                                image_paths.extend(glob.glob(path + '/*.webp', recursive=False))\n\n                        # iterate through mask directories and add mask paths to list\n                        for mask_folder in mask_folders:\n                            path = os.path.join(classe_directory, mask_folder)\n                            if os.path.exists(path):\n                                mask_paths.extend(glob.glob(path + '/*.[jJ][pP][gG]', recursive=False))\n                                mask_paths.extend(glob.glob(path + '/*.[jJ][pP][eE][gG]', recursive=False))\n                                mask_paths.extend(glob.glob(path +'/*.png', recursive=False))\n                                mask_paths.extend(glob.glob(path + '/*.webp', recursive=False))\n\n                    # create dataframe from image and mask paths\n                    data = {'X': image_paths, 'Y': mask_paths}\n                    dataset = pandas.DataFrame(data)\n                    \n                elif (self.problem == \"mix\"):\n                    pass\n        \n            elif (data_type == \"audio\"):\n                pass\n            elif (data_type == \"video\"):\n                pass\n            elif (data_type == \"mix\"):\n                pass\n            \n            \n            self.data = dataset\n            \n            end_time = time.process_time()\n\n            self.data_loading_time = end_time - start_time\n            \n            print(\"Data Loading Time: {0} minutes, {1:.3f} seconds\".format(int(self.data_loading_time/60), self.data_loading_time%60))\n            \n        else:\n            # TODO check if dataset\n            self.data = data\n            #TODO check if connection\n        \n        self.data_loaded = True\n        \n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        \n        if (self.data_type == \"image\" and self.problem == \"segmentation\" and\n            self.problem_type == \"supervised\"):\n            \n            X = self.data.loc[index][\"X\"]\n            Y = self.data.loc[index][\"Y\"]\n            \n            X = numpy.array(Image.open(X_directory).convert(\"RGB\"))\n            Y = numpy.array(Image.open(Y_directory).convert(\"L\"), dtype=np.float32)\n            Y[Y == 255.0] = 1.0\n            \n            if self.transform is not None:\n                augmentations = self.transform(image=image, mask=mask)\n                image = augmentations[\"image\"]\n                mask = augmentations[\"mask\"]\n            \n            img_path = os.path.join(self.image_dir, self.images[index])\n            mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".jpg\", \"_mask.gif\"))\n        \n\n        \n\n        return X, Y\n    \n    \n    def get_random_sample (self, sample_number = 2, img_show = False, img_transform = False):\n        \n        if (self.data_type == \"image\" and self.problem == \"segmentation\" and\n            self.problem_type == \"supervised\"):\n            \n            \n            samples_index = numpy.random.randint(self.__len__(), size = sample_number)\n            \n            print(samples_index)\n            \n            X_directory = self.data.loc[samples_index][\"X\"]\n            Y_directory = self.data.loc[samples_index][\"Y\"]\n        \n        \n            if (img_transform == True):\n                pass\n        \n            if (img_show == True):\n                \n                fig, axes = matplotlib.pyplot.subplots(nrows=sample_number, ncols=2, figsize = (8,5*sample_number))\n                \n                \n                for i in range(0, len(samples_index), 1):\n                    \n                    \n                    X_img = cv2.imread(X_directory[samples_index[i]])\n                    Y_img = cv2.imread(Y_directory[samples_index[i]])\n                \n                    axes[i][0].imshow(X_img)\n                    axes[i][1].imshow(Y_img)\n                    \n                    axes[i][0].set_title(X_directory[samples_index[i]], fontsize=8)\n                    axes[i][1].set_title(Y_directory[samples_index[i]], fontsize=8)\n                \n                matplotlib.pyplot.show()\n        \n        else:\n            pass\n        \n        return X_directory, Y_directory\n    \n    def analize_sample (self, index = None, sample = None, with_model = False):\n        \n        image = cv2.imread(image_path)\n        height, width, channels = image.shape\n        laplacian = numpy.array(cv2.Laplacian(image, cv2.CV_64F))\n        \n    def evaluate_data (self):\n        \n        start_time = time.process_time()\n        \n        if (self.data_loaded == False):\n            #TODO raise error\n            return\n        \n        if (self.data_type == \"image\"):\n            \n            keys = [\"height\", \"width\", \"channels\", \"quality\"]\n            keys_special = [\"histogram\", \"\"]\n            \n            \n            def img_info(image_path):\n                \n                image = cv2.imread(image_path)\n                height, width, channels = image.shape\n                \n                hist_blue = cv2.calcHist([image], [0], None, [256], [0, 256])\n                hist_green = cv2.calcHist([image], [1], None, [256], [0, 256])\n                hist_red = cv2.calcHist([image], [2], None, [256], [0, 256])\n                quality = 1\n                \n                data = {\n                    \"height\":height,\n                    \"width\":width,\n                    \"channels\":channels,\n                    \"histogram\":[hist_red, hist_green, hist_blue],\n                    \"quality\":quality\n                }\n                return data\n            \n            \n            if (self.problem_type == \"supervised\"):\n                \n                X_info = numpy.array(self.data[\"X\"].apply(img_info))\n                Y_info = numpy.array(self.data[\"Y\"].apply(img_info))\n            \n                X_features = []\n                Y_features = []\n            \n                for key in keys:\n\n\n                    X_features.append([len([data.get(key) for data in X_info]),\n                                       numpy.max([data.get(key) for data in X_info]),\n                                       numpy.min([data.get(key) for data in X_info]),\n                                       numpy.mean([data.get(key) for data in X_info]),\n                                       numpy.median([data.get(key) for data in X_info]),\n                                       numpy.std([data.get(key) for data in X_info]),\n                                       numpy.unique([data.get(key) for data in X_info])])\n\n\n                    Y_features.append([len([data.get(key) for data in Y_info]),\n                                       numpy.max([data.get(key) for data in Y_info]),\n                                       numpy.min([data.get(key) for data in Y_info]),\n                                       numpy.mean([data.get(key) for data in Y_info]),\n                                       numpy.median([data.get(key) for data in Y_info]),\n                                       numpy.std([data.get(key) for data in Y_info]),\n                                       numpy.unique([data.get(key) for data in Y_info])])\n\n\n\n                fig, axes = matplotlib.pyplot.subplots(2,2, figsize = (10,8))\n\n\n\n                X_histogram_average = numpy.mean([data.get(\"histogram\") for data in X_info], axis = 0)            \n                Y_histogram_average = numpy.mean([data.get(\"histogram\") for data in Y_info], axis = 0)\n                \n                axes[0][0].plot(X_histogram_average[0], color = \"red\")\n                axes[0][0].plot(X_histogram_average[1], color = \"green\")\n                axes[0][0].plot(X_histogram_average[2], color = \"blue\")\n                \n                axes[0][0].set_title(\"Average RGB Histogram X\")\n                \n                axes[0][1].plot(Y_histogram_average[0], color = \"red\")\n                axes[0][1].plot(Y_histogram_average[1], color = \"green\")\n                axes[0][1].plot(Y_histogram_average[2], color = \"blue\")\n                \n                axes[0][1].set_title(\"Average RGB Histogram Y\")\n                \n                \n                X_img = cv2.imread(self.data.loc[random.randint(0, self.__len__())][\"X\"])\n                # Convert to grayscale\n                gray = cv2.cvtColor(X_img, cv2.COLOR_BGR2GRAY)                \n                laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n                \n                axes[1][0].imshow(laplacian, cmap = \"gray\")\n                axes[1][0].set_title(\"Laplacian\")\n\n\n                dataset_X = pandas.DataFrame(X_features, \n                                           columns = [\"count\", \"max\",\"min\",\"average\",\"median\",\"std\", \"unique\"],\n                                           index = keys)\n\n                dataset_Y = pandas.DataFrame(X_features, \n                                           columns = [\"count\", \"max\",\"min\",\"average\",\"median\",\"std\", \"unique\"],\n                                           index = keys)\n\n                delta = time.process_time() - start_time\n                print(\"Data Evaluation Time: {0} hours, {1} minutes, {1:.3f} seconds\".format(int(delta/24), int(delta/60), delta%60))\n\n\n                matplotlib.pyplot.show()\n                \n                return dataset_X, dataset_Y\n            \n    def preprocessing (self):\n        \n        print(\"Preprocessing Process Initiated\")\n        \n        def data_augementation (self):\n            pass\n        def data_sythesis(self):\n            pass\n        print(\"Preprocessing Process Completed\")\n        pass\n   \n    def train_test_split(self, test_factor, seed):\n        \n        self.test_factor = test_factor\n        \n        if (seed is None):\n                X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(\n                    self.data[\"X\"],\n                    self.data[\"Y\"],\n                    test_size = test_factor)\n                \n        else:\n                X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(\n                    self.data[\"X\"],\n                    self.data[\"Y\"],\n                    test_size = test_factor,\n                    random_state = seed)\n            \n        \n        self.data_train = pandas.concat([X_train, Y_train], axis = 1)\n        self.data_test = pandas.concat([X_test, Y_test], axis = 1)\n            \n        self.train_size = len(self.data_train)\n        self.test_size = len(self.data_test)\n\n        \n        fig, axes = matplotlib.pyplot.subplots(1,1, figsize = (3,3))\n        plot = axes.bar([\"Train\", \"Test\"], [self.train_size, self.test_size])\n        axes.set_title(\"Train Test Split Factor: {}\".format(self.test_factor))\n        axes.set_xlabel(\"Datasets\")\n        axes.set_ylabel(\"Sample Count\")\n        \n        '''\n        for rect, label in plot:\n            height = rect.get_height()\n            top = height\n            ax.text(rect.get_x() + rect.get_width() / 2, height + 5, top , ha=\"center\", va=\"bottom\")\n        '''\n        #axes.set_grid()\n        #axes.legend()\n        matplotlib.pyplot.show()\n            \n            \n    def init_dataloader(self, for_training = True, batch_size = 32, multiple_processes = 2, shuffle = True, drop_last = False):           \n\n        if (for_training == True):\n            \n            class Auxiliar(torch.utils.data.Dataset):\n                def __init__(self, data):\n                    self.data = data\n        \n                def __getitem__(self, index):\n                    x, y = self.data[index]\n                    return (x, y)\n    \n                def __len__(self):\n                    return len(self.data)\n            \n            train = Auxiliar(self.data_train)\n            test = Auxiliar(self.data_test)\n\n            self.Dataloader_train = torch.utils.data.DataLoader(train,\n                                                  batch_size = batch_size,\n                                                  num_workers = multiple_processes,\n                                                  shuffle = shuffle,\n                                                  drop_last = drop_last)\n\n            self.Dataloader_test = torch.utils.data.DataLoader(test,\n                                                  batch_size = batch_size,\n                                                  num_workers = multiple_processes,\n                                                  shuffle = shuffle,\n                                                  drop_last = drop_last)\n\n\n        elif (for_training == False):\n\n          #Not for training. For predicting\n          self.Dataloader = torch.utils.data.DataLoader(self.dataset,\n                                                  batch_size = 1,\n                                                  num_workers = multiple_processes,\n                                                  shuffle = shuffle,\n                                                  drop_last = drop_last)\n\n        print(\"DataLoader Process Complete\")\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_directory = r\"../input/crack-dataset/Concrete\"\ndata = customDataset(data = data_directory, test_factor = 0.2, data_type = \"image\",\n                 transform = None, multiple_processes = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.get_random_sample(5, img_show = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.evaluate_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.initiate_process(multiple_processes = 1, batch_size = 32, shuffle = True, drop_last = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn\nimport torch.nn.functional\nimport torchvision\nimport torchvision.transforms\n\n\n\nclass Layer ():\n\n    def __init__(self, type, activationFunction) -> None:\n        super().__init__()\n    \n        self.layer = type\n        self.activationFunction = activationFunction\n\n    def forward (self, X):\n\n        if self.activationFunction is not None:\n            return self.activationFunction(self.layer(X))\n        \n        return self.layer(X)\n\n\n\nclass DoubleConvolutionBlock ():\n\n    def __init__(self, channels_input, channels_output:int, mode, final_output = 1) -> None:\n        super().__init__()\n\n        self.channels_input = channels_input\n        self.channels_output = channels_output\n        if (mode.lower() == \"final\"):\n            self.final_output = final_output\n\n        self.layers = []\n\n        self.build(mode)\n\n    \n    def build (self, mode):\n\n        layer1 = torch.nn.Conv2d(in_channels = self.channels_input, \n        out_channels = self.channels_output, kernel_size = (3,3),\n                                stride = 1, padding = 1, dilation = 1, bias = True,\n                                padding_mode = \"zeros\", device=None)\n\n        activation1 = torch.nn.functional.relu\n\n\n\n        layer2 = torch.nn.Conv2d(in_channels = self.channels_output, \n        out_channels = self.channels_output, kernel_size = (3,3),\n                                stride = 1, padding = 1, dilation = 1, bias = True,\n                                padding_mode = \"zeros\", device=None)\n        activation2 = torch.nn.functional.relu\n\n\n        if (mode == \"Down\"):\n            #layer3 = torch.nn.MaxPool2d(kernel_size = (2, 2), stride = 2, padding=0, dilation=1)\n            #activation3 = None\n            self.layers.append(Layer(layer1, activation1))\n            self.layers.append(Layer(layer2, activation2))\n\n        elif (mode == \"Up\"):\n            layer3 = torch.nn.ConvTranspose2d(self.channels_output, (self.channels_output)//2,\n             kernel_size = (2, 2), stride=2, padding=0, dilation=1)\n            activation3 = None\n            \n            self.layers.append(Layer(layer1, activation1))\n            self.layers.append(Layer(layer2, activation2))\n            self.layers.append(Layer(layer3, activation3))\n\n        elif (mode == \"Final\"):\n\n            layer3 = torch.nn.Conv2d(in_channels = self.channels_output, out_channels = self.final_output,\n             kernel_size = (1,1),stride = 1, padding = 0, dilation = 1, bias = True,\n                                padding_mode = \"zeros\", device=None)            \n            activation3 = None\n\n            self.layers.append(Layer(layer1, activation1))\n            self.layers.append(Layer(layer2, activation2))\n            self.layers.append(Layer(layer3, activation3))\n\n        \n        \n\n    def forward (self, X):\n\n        for layer in self.layers:\n\n            X = layer.forward(X)\n        \n        return X\n\n\n\nclass Model ():\n\n    def __init__(self, channels_input = 3, channel_output = 3, img_size = (255, 255)) -> None:\n        \n\n        self.channels_input = channels_input\n        self.channel_output = channel_output\n\n        self.layers = []\n\n        self.built = False\n        self.trained = False\n        \n        \n        self.problem = \"segmentation\"\n        self.problem_type = \"supervised\"\n                \n\n    def build(self):\n\n        \n        # Encoder Chain\n        # The contracting path follows the typical architecture of a convolutional network.\n        # It consists of the repeated application of two 3×3 convolutions\n        # (unpadded convolutions), each followed by a rectified linear unit (ReLU)\n        # and a 2×2 max pooling operation with stride 2 for downsampling.\n        # At each downsampling step we double the number of feature channels.\n\n        self.block1 = DoubleConvolutionBlock(self.channels_input, 64, \"Down\")\n        self.block2 = DoubleConvolutionBlock(64, 128, \"Down\")\n        self.block3 = DoubleConvolutionBlock(128, 256, \"Down\")\n        self.block4 = DoubleConvolutionBlock(256, 512, \"Down\")\n\n    \n        # Decoder Chain\n        # Every step in the expansive path consists of an upsampling of the feature map\n        # followed by a 2×2 convolution (“up-convolution”) that halves the number\n        # of feature channels, a concatenation with the correspondingly cropped feature map\n        # from the contracting path, and two 3×3 convolutions, each followed by a ReLU\n\n        self.block5 = DoubleConvolutionBlock(512, 1024, \"Up\")\n        \n        self.block6 = DoubleConvolutionBlock(1024, 512, \"Up\")\n        self.block7 = DoubleConvolutionBlock(512, 256, \"Up\")\n        self.block8 = DoubleConvolutionBlock(256, 128, \"Up\")\n\n        self.block9 = DoubleConvolutionBlock(128, 64, \"Final\", self.channel_output)\n    \n\n        self.built = True\n\n    def forward (self, X):\n\n        self.connections = []\n\n        X = self.block1.forward(X)\n        self.connections.append(X)\n        X = torch.nn.MaxPool2d(kernel_size = (2, 2), stride = 2, padding=0, dilation=1)(X)\n\n        X = self.block2.forward(X)\n        self.connections.append(X)\n        X = torch.nn.MaxPool2d(kernel_size = (2, 2), stride = 2, padding=0, dilation=1)(X)\n\n        X = self.block3.forward(X)\n        self.connections.append(X)\n        X = torch.nn.MaxPool2d(kernel_size = (2, 2), stride = 2, padding=0, dilation=1)(X)\n\n        X = self.block4.forward(X)\n        self.connections.append(X)\n        X = torch.nn.MaxPool2d(kernel_size = (2, 2), stride = 2, padding=0, dilation=1)(X)\n\n\n\n\n        X = self.block5.forward(X)\n        \n        \n        if (X.shape != self.connections[-1].shape):\n            X = torchvision.transforms.functional.resize(X, size = self.connections[-1].shape[2:])\n        X = torch.cat((self.connections[-1], X), dim = 1)\n        X = self.block6.forward(X)\n\n        if (X.shape != self.connections[-2].shape):\n            X = torchvision.transforms.functional.resize(X, size = self.connections[-2].shape[2:])\n        X = torch.cat((self.connections[-2], X), dim = 1)\n        X = self.block7.forward(X)\n        \n        if (X.shape != self.connections[-3].shape):\n            X = torchvision.transforms.functional.resize(X, size = self.connections[-3].shape[2:])\n        X = torch.cat((self.connections[-3], X), dim = 1)\n        X = self.block8.forward(X)\n\n        if (X.shape != self.connections[-4].shape):\n            X = torchvision.transforms.functional.resize(X, size = self.connections[-4].shape[2:])\n        X = torch.cat((self.connections[-4], X), dim = 1)\n        \n        \n        return self.block9.forward(X)\n\n\n    def build_UNet_modified(self) -> None:\n\n        #TODO\n\n\n        layer1 = torch.nn.Conv2d(in_channels = 3, out_channels = 127, kernel_size = (3,3),\n                                stride = 1, padding = 1, dilation = 1, bias = False,\n                                padding_mode = \"same\", device=None)\n        activation1 = None\n\n        layer2 = torch.nn.BatchNorm2d(32)\n        activation2 = torch.nn.functional.relu\n\n\n        layer3 = torch.nn.Conv2d(in_channels = 3, out_channels = 127, kernel_size = (3,3),\n                                stride = 1, padding = 1, dilation = 1, bias = False,\n                                padding_mode = \"same\", device=None)\n        activation3 = None\n\n        \n        layer4 = torch.nn.BatchNorm2d(32)\n        activation4 = torch.nn.functional.relu\n\n\n\n        layer5 = torch.nn.MaxPool2d(kernel_size = (2, 2), stride = 2)\n        activation5 = None\n\n        \n        self.layers.append(Layer(layer1, activation1))\n        self.layers.append(Layer(layer2, activation2))\n        self.layers.append(Layer(layer3, activation3))\n        self.layers.append(Layer(layer4, activation4))\n        self.layers.append(Layer(layer5, activation5))\n\n        #Down Block\n    \n\n\n\n\n        self.built = True\n\n\n    def debbugFoward (self):\n\n        batch_size = 5\n        img_size = 160\n        X = torch.randn((batch_size, self.channels_input, img_size, img_size))\n\n        if (self.built == False):\n            self.build()\n\n        pred = self.forward(X)\n        print(\"Input Shape: \", X.shape)\n        print(\"Predict Shape: \", pred.shape)\n        \n        condition = (batch_size == pred.shape[0]) and (pred.shape[1] == self.channel_output)\n\n        assert condition, AssertionError\n\n        return True\n\n    def summary(self):\n        \n        if(self.problem == \"segmentation\"):\n            torchsummary.summary(self, (self.channels_input, 200, 200))\n   \n    def loadModel (self, path):\n        self.load_state_dict(torch.load(path))\n        \n    def saveModel(self, path):\n        torch.save(self.state_dict(), path)\n        \n    def eval(self):\n        pass\n    \n    \n\nm = Model(channels_input = 3, channel_output = 1)\n\nm.debbugFoward()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Project","metadata":{}},{"cell_type":"code","source":"class Project():\n    \n    def __init__ (self, model, dataset, problem, problem_type,\n                   ):  \n        \n        \n        self.parameter_check(problem, problem_type)\n        \n        self.model = model\n        self.dataset = dataset\n        \n        self.dataset.problem = self.problem\n        self.dataset.problem_type = self.problem_type\n        \n        \n        \n        self.savePath = None\n        \n        \n    def parameter_check(problem, problem_type):\n        \n        problem = problem.lower()\n        if (problem != \"regression\" or problem != \"classification\" or\n            problem != \"detection\" or problem != \"segmentation\" or\n            problem != \"anomaly\" or problem != \"mix\"):\n            \n            #TODO\n            pass\n        \n        self.problem = problem\n        \n        problem_type = problem_type.lower()\n        if (problem_type != \"supervised\" or problem_type != \"unsupervised\" or\n            problem_type != \"reinforcement\" or problem_type != \"semi-supervised\" or\n            problem_type != \"transfer\" or problem_type != \"active\" or \n            problem_type != \"generative\" or problem_type != \"recommendation\"):\n            \n            #TODO\n            pass\n        \n        self.problem_type = problem_type\n        \n        \n        \n    def problem_summary(self):\n        \n        \n    def train_batch(self, data):\n        \n        if (self.problem_type == \"supervised\" and\n            self.problem_type == \"classification\"):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n\n            inputs = inputs.to(self.device)\n            labels = labels.to(self.device)\n        \n            # track history if only in train\n            with torch.set_grad_enabled(True):\n                \n                # 1. Forward pass\n                # forward + backward + optimize\n                if(self.model.baseModel is None):\n                    y_pred = self.model.forward(inputs)\n                else:\n                    y_pred = self.model.baseModel(inputs)\n                    \n                # 2. Calculate  and accumulate loss\n                loss = self.function_loss(y_pred, labels)\n                \n                # 3. Optimizer zero grad\n                self.optimizer.zero_grad()\n                \n                # 4. Loss backward\n                loss.backward()\n                \n                # 5. Optimizer step\n                self.optimizer.step()\n            # Calculate and accumulate accuracy metric across all batches\n            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n            \n            #y_pred_class = torch.argmax(y_pred, dim=1)\n            acc = (y_pred_class == labels).sum().item()/len(y_pred)\n        \n        return loss.item(), acc\n    \n    \n    \n    def train_fold(self, n_epoch, train_loader, best_batch_show = True):\n        \n        #Epochs\n        for epoch in range (0, n_epoch, 1):\n\n            epoch_start = time.time()\n\n            train_loss = []\n            train_acc = []\n            best_batch_acc = 0.0\n            best_batch_loss = 999\n            best_batch_iteration = 0\n\n            data_10 = 0\n            i = 1\n\n            #train iteration\n            if (best_batch_show is True):\n                print(\"Epoch {0}\".format(epoch+1), end = \": \")\n\n\n            for batch_i, data in enumerate(train_loader):\n\n                loss, acc = self.train_batch(data)\n                data_10 += len(data)\n\n                # print statistics\n                if (best_batch_show is not True):\n                    print(\"Epoch:{0} Batch:{1} Loss = {2:0.4f} Accuracy = {3:0.4f}\".format(epoch+1, batch_i+1, loss, acc))\n\n                elif (best_batch_show is True):\n\n                    if (best_batch_acc < acc and best_batch_loss > loss):\n                        best_batch_acc = acc\n                        best_batch_loss = loss\n                        best_batch_iteration = batch_i\n\n                    if (data_10 > self.dataset.trainSize/10 * i):\n                        print(\"{0}-\".format(i), end = \"\")\n                        i += 1\n\n                self.train_scores.append([epoch+1, data_10, loss, acc])\n\n                train_loss.append(loss)\n                train_acc.append(acc)\n    \n    \n    def trainModel (self, batch_size = 32, n_epochs = 5, KFolds = 0,\n                    function_loss = None, optimizer = None,\n                    learning_rate = None, device = None, multiple_processes = 2,\n                    best_batch_show = True, savePath = None, debbugMode = False,\n                    debbugFile_Path = None):\n        \n        self.nEpoch = n_epochs\n        self.KFolds = KFolds\n\n        \n                \n        self.train_scores = []            #scores of model as number sample increase\n        self.train_scores_epochs = []     #scores of model as epoch increase\n        self.cv_scores_epochs = []  \n\n        train_start = time.process_time()\n        \n\n        print(\"************************************************************\")\n        print(\"Model Training on: {0}\".format(self.device))\n\n        if (self.KFolds > 0):\n            \n            cv_splits = sklearn.model_selection.KFold(n_splits = KFolds, shuffle=True)\n            \n            for fold, (train_index, cv_index) in enumerate(cv_splits.split(numpy.arange(len(self.dataset.data_train)))):\n                \n                print(\"Fold: {0}/{1}\".format(fold, self.KFolds),sep = \"\\n\")\n                \n                train_sampler = torch.utils.dataSubsetRandomSampler(train_index)\n                cv_sampler = torch.utils.dataSubsetRandomSampler(cv_index)\n                \n                train_loader = torch.utils.data.DataLoader(self.dataset.dataset_train, batch_size = self.dataset.batch_size, sampler = train_sampler, drop_last = False)\n                cv_loader = torch.utils.data.DataLoader(self.dataset.dataset_train, batch_size = self.dataset.batch_size, sampler = cv_sampler, drop_last = False)\n                \n                \n                self.train_fold(n_epoch = n_epochs, train_loader = train_loader, best_batch_show = best_batch_show)\n                \n                #Validation iteration\n\n                if (best_batch_show is True):\n                    print(\"Epoch {0}\".format(epoch+1), end = \": \")\n                \n                for batch_i, data in enumerate(cv_loader):\n                    loss, acc = self.train_batch(data)\n                    \n                    cv_loss.append(loss)\n                    cv_acc.append(acc)\n\n             \n                if (best_batch_show is True):\n                    print(\"\\nBest_Batch:{0} Best_Batch_Loss = {1:0.4f} Best_Batch_Accuracy = {2:0.4f}\".format(best_batch_iteration+1, best_batch_loss, best_batch_acc))\n            \n                # Adjust metrics to get average loss and accuracy per batch \n                train_loss_avg = sum(train_loss) / len(self.dataset.Dataloader_train)\n                train_acc_avg = sum(train_acc) / len(self.dataset.Dataloader_train)\n\n                self.train_scores_epochs.append([epoch+1, train_acc, train_loss, float((time.time() - epoch_start) // 60), (time.time() - epoch_start) % 60])\n\n                # print statistics\n                print(\"Epoch:{0} Loss_Avg = {1:.4f} Accuracy_Avg = {2:.4f} Time Lapsed = {3}min {4:.2f}seg\\n\".format(\n                    epoch+1, train_loss_avg, train_acc_avg, (time.time() - epoch_start) // 60, (time.time() - epoch_start) % 60))\n        \n\n        \n        elif (self.KFolds <= 0):\n            #no cv\n            ###################################################\n\n            self.train_fold(n_epoch = n_epochs, train_loader = train_loader, best_batch_show = best_batch_show)\n\n            if (best_batch_show is True):\n                print(\"\\nBest_Batch:{0} Best_Batch_Loss = {1:0.4f} Best_Batch_Accuracy = {2:0.4f}\".format(best_batch_iteration+1, best_batch_loss, best_batch_acc))\n\n            # Adjust metrics to get average loss and accuracy per batch \n            train_loss_avg = sum(train_loss) / len(self.dataset.Dataloader_train)\n            train_acc_avg = sum(train_acc) / len(self.dataset.Dataloader_train)\n\n            self.train_scores_epochs.append([epoch+1, train_acc, train_loss, float((time.time() - epoch_start) // 60), (time.time() - epoch_start) % 60])\n\n\n            # print statistics\n            print(\"Epoch:{0} Loss_Avg = {1:.4f} Accuracy_Avg = {2:.4f} Time Lapsed = {3}min {4:.2f}seg\\n\".format(\n                    epoch+1, train_loss_avg, train_acc_avg, (time.time() - epoch_start) // 60, (time.time() - epoch_start) % 60))\n\n\n            \n            \n            \n        delta_training = time.process_time() - train_start\n        print(\"Model Training Time: {0} hours, {1} minutes, {2:.3f} seconds, {} seconds\".format(\n                int(delta_training/24),int(delta_training/60), delta_training%60)) \n        print(\"************************************************************\")\n    \n    \n        \n        self.model.trained = True\n        if (savePath is not None):\n            self.savePath = savePath\n            self.model.saveModel(savePath)\n\n\n        if (debbugMode is True and debbugFile_Path is not None):\n            file_object = open(debbugFile_Path, 'w')\n            for data in self.train_scores_epochs:\n                file_object.write(str(data[0]))\n                file_object.write('|')\n                file_object.write(str(data[1]))\n                file_object.write('|')\n                file_object.write(str(data[2]))\n                file_object.write('|')\n                file_object.write(str(data[3]))\n                file_object.write('|')\n                file_object.write(str(data[4]))\n\n                file_object.write(\"\\n\")\n            #Close the file\n            file_object.close()\n\n\n\n        #self.plot_learning_curve()\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uNet = Model()\nuNet.__summary__()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]}]}